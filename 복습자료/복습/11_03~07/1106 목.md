# 1106 목

</br>
</br>
</br>

#### 간단 복습

</br>

- 평균(mean):   수치형 컬럼, 극단치 영향 없을 시 사용
- 중앙(median): 수치형 컬럼, 극단치가 있을 시 사용
- 최빈(mode):   범주형 컬럼, 대표값인 최빈값으로 대체

</br>

>SimpleImputer

- 결측값 대체, 평균, 중앙, 최빈값으로 대체
- strategy: 어떤 값으로 대체할 지 지정

</br>

>KNNImputer

- 최근접 이웃을 찾아 그 이웃들의 값을 평균내어 결측치 대체

</br>

>공통 메소드

- fit():    변환할 때 필요한 값을 찾아서 instance변수에 저장
- transform():  fit에서 찾은 값을 이용하여 결측치 대체
- fit_transform():  fit, tranform을 순서대로 한 번에 처리


</br>
</br>
</br>

## 범주형 데이터 전처리

</br>

#### 레이블 인코팅

>범주형 Feature의 고유값들을 오름차순으로 정렬 후 1씩 증가

- 숫자의 크기의 차이가 모델에 영향을 주지 않는 트리 계열 모델 (의사결정나무, 랜덤 포레스트)에 적용
- 숫자의 크기의 차이가 모델에 영향을 주는 선형 계열 모델(로지스틱회귀 등)에는 사용하면 안됨

</br>

>sklearn.preprocessing.LableEncoder 사용

- fit:      어떻게 변환할 지 학습
- tranform: 문자열을 숫자로 변환
- fit_tranform:     학습과 변환을 한 번에 처리
- inverse_transforn:    숫자를 문자로 변환
- classes_: 인코딩한 클래스 조회

</br>
</br>

<code>
<pre>

import pandas as pd
#LabelEncoder는 1차원 자료구조(iterable)을 받아서 변환.
items = pd.Series(['TV', '냉장고', '컴퓨터', '컴퓨터', '냉장고', '에어콘',  'TV', '에어콘'])


import numpy as np
from sklearn.preprocessing import LabelEncoder

#LabelEncoder의 instance 생성
le = LabelEncoder()

#학습: 각 고유값들을 어떤 정수로 바꿀지 계산.
le.fit(['TV', '냉장고', '컴퓨터', '에어콘', '공기 청정기', '정수기'])  # 인코딩 대상을 넣어 학습한다.

#변환: 학습 결과에 맞춰서 값들을 변환
result1 = le.transform(items)

print(result1)
#[0 2 5 5 2 3 0 3]


</pre>
</code>


</br>
</br>
</br>


#### one-Hot Encording

- 정답에 해당하는 열을 1로 나머지는 0
- 선형 계열 모델에서 범주형 데이터 변환시 사용

</br>

>One-Hot Encording 변환 처리
- fit:  어떻게 변환할 지 학습
- tranform:     원핫인코딩 처리
- fit_tranform: 학습과 변환을 한 번에 처리
- get_feature_name_out: 원핫인코딩 된 것을 Feature로 이름 반환
- 데이터셋은 2차원 배열을 전달하여 Feature별로 원핫인코딩 처리한다



<code>
<pre>

import numpy as np
#원핫 인코딩은 열 단위로 처리하므로 2차원 형태의 자료구조를 입력한다.

items=np.array([['TV'],['냉장고'],['전자렌지'],['컴퓨터'],['선풍기'],['선풍기'],['믹서'],['믹서']])
print(np.shape(items))

from sklearn.preprocessing import OneHotEncoder
#객체 생성
ohe = OneHotEncoder()
#학습 - 어떻게 바꿀지 학습.
ohe.fit(items)
#변환
result = ohe.transform(items)
#ohe.fit_transform(items)

result.toarray() #ndarray로 변환.
array([[1., 0., 0., 0., 0., 0.],
       [0., 1., 0., 0., 0., 0.],
       [0., 0., 0., 0., 1., 0.],
       [0., 0., 0., 0., 0., 1.],
       [0., 0., 0., 1., 0., 0.],
       [0., 0., 0., 1., 0., 0.],
       [0., 0., 1., 0., 0., 0.],
       [0., 0., 1., 0., 0., 0.]])



get_feature_name_out()
#각 열이 어떤 class를 나타내는지 조회하는 방법


</pre>
</code>


</br>
</br>
</br>


## 수치형 데이터 전처리

</br>

#### Feature Scaling (정규화)

- 각 Feature들 간의 값의 범위가 다를 경우 이 값의 범위를 일정한 범위로 맞춤 (예:M,Kg)
- 트리계열을 제외한 대부분 머신러닝 알고리즘들이 Feature간의 서로 다른 척도에 영향을 받는다
- Scaling은 Train set으로 Fitting한다.

</br>

>메소드

- fit: 2차원 배열을 받으면 0축 기준으로 학습
- tranform: 2차원 배열을 받으며 0축을 기준으로 변환
- fit_tranform: 학습과 변환 한 번에 처리
- inverse_tranform: 변환된 값을 원래 값으로 복원

</br>
</br>

#### 표준화 (StandardScaler)

>Feature 값들 평균이 0이고 표준편차가 1인 범위에 있도록 변환한다



<code>
<pre>

import numpy as np
data = np.array([[10], [2], [30]])  
#ndarray 생성.

m = data.mean() # 평균      (14.0)
s = data.std()  # 표준편차  (11.7)

result = (data - m)/s
#array([[-0.33968311],
       [-1.01904933],
       [ 1.35873244]])



####위 과정을 간소화 한 과정####

from sklearn.preprocessing import StandardScaler
#객체 생성
s_scaler = StandardScaler()
#어떻게 변환할지 학습 
s_scaler.fit(data)
#변환
result2 = s_scaler.transform(data)
#result3 = s_scaler.fit_transform(data) # 학습/변환 대상이 같은 경우.
result2
#array([[-0.33968311],
       [-1.01904933],
       [ 1.35873244]])

</pre>
</code>

</br>
</br>

#### MinMaxScaler

>데이터셋의 모든 값을 0과 1 사이 값으로 반환한다


<code>
<pre>

data = np.array([[10], [2], [30]])

minimum = data.min()
maximum = data.max()

result = (data - minimum) / (maximum - minimum)
#array([[0.28571429],
       [0.        ],
       [1.        ]])



####위 과정을 간소화 한 과정####
from sklearn.preprocessing import MinMaxScaler

#객체 생성
mm_scaler = MinMaxScaler()
#학습
mm_scaler.fit(data)
#변환
result2 = mm_scaler.transform(data)
#result3 = mm_scaler.fit_transform(data)  # 학습/변환 대상이 같은 경우.
result2

#array([[0.28571429],
       [0.        ],
       [1.        ]])

</pre>
</code>


</br>
</br>
</br>


## 모델 평가

</br>

#### 분류와 회귀의 평가방법

>분류 평가 지표
- 정확도 (Accuracy)
- 정밀도 (Precision)
- 재현률 (Recall)
- F1점수 (F1 Score)
- PR Curve, AP score
- ROC, AUC score

</br>

#### 회귀 평가방법
- MSE (Mean Squared Error)
- RMSE (Root Mean Squared Error)
- R2 (결정계수)

</br>
</br>

#### 이진 분류

>특정 클래스인지 아닌지를 분류한다
- 환자인가 (양성1, 음성0)
- 스팸메일인가 (스팸1, 정상0)
- 사기거래인가 (사기1, 정상0)

</br>

>찾으려는 대상이 True이면 1, 아니면 0으로 표현함


</br>
</br>
</br>

#### 정확도

>전체 데이터를 기준으로 평가한다. 클래스별 성능 평가가 안된다.



</br>
</br>
</br>


#### 혼돈 행열

>실제 값과 예측한 것으로 표로 만든 평가표

</br>

- 함수:     confusion_matrix(정답, 모델예측값)
- 0번축:    실제(정답) class
- 1번축:    예측 calss
- cell:     개수

</br>

## 꼭 암기해야 할 것

>TP (True Positive)
- 양성으로 예측했는데 맞은 개수

>TN (True Negative)
- 음성으로 예측했는데 맞은 개수

>FP (False Positive)
- 양성으로 예측했는데 틀린 개수
- 음성을 양성으로 예측

>FN (False Negative)
- 음성으로 예측했는데 틀린 개수
- 양성을 음성으로 예측

</br>
</br>

#### 양성 예측력 측정 평가지표

>Recall/Sensivity (재현율/민감도)
- 실제 양성을 양성으로 예측한 것의 비율
- TPR(True Positive Rate)

>Precision (정밀도)
- 양성 예측한 것 중 실제 양성인 비율
- PPV(Positive Predictive Value)

>F1 점수
- 정밀도와 재현율의 조화평균 점수
- 두 개가 비슷할 수록 높은 갚을 가지게 된다.
- F1점수가 높다는 뜻은 어느하나 치우치지 않고 좋다고 판단할 수 있는 근거가 된다


</br>
</br>

#### 음성 예측력 측정 평가지표

>Specificty (특이도)
- 실제 음성인 것들 중 음성으로 맞게 예측한 비율
- TNR (True Negative Rate)

>Fall out (위양성률)
- 실제 음성인 것들 중 양성으로 잘못 예측한 비율
- FPR (False Positive Rate)


</br>
</br>

#### 다중분류

>다중분류 평가에서 사용할 경우 average에 설정한다
- micro:    class 상관없이 전체 클래스 기준 계산
- macro:    class 별로 계산한 뒤 평균을 낸다
- weighted: class 별로 계산한 뒤 데이터 수에 따라 가중치 평균을 낸다


</br>
</br>


## 머신모델을 이용해 학습

>DecisionTreeClassifier
>RandomForestClassifier

<code>
<pre>

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=0)

#####DecisionTreeClassifier#####
from sklearn.tree import DecisionTreeClassifier

#모델 생성
tree = DecisionTreeClassifier(max_depth=3)

#학습
tree.fit(X_train, y_train)

#추론
pred_train_tree = tree.predict(X_train)
pred_test_tree = tree.predict(X_test)

----------------------------------------------

#Confusion Matrix
cm_train = confusion_matrix(y_train, pred_train_tree)
cm_test =  confusion_matrix(y_test, pred_test_tree)

print(f"train set\n{cm_train}")
print("-"* 20)
print(f"test set\n{cm_test}")

</pre>
</code>




